{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_file_path = r'C:\\Users\\User\\Desktop\\Lighthouse BootCamp\\Statistical-Modelling-Project\\merged_df.csv'\n",
    "merged_df = pd.read_csv(csv_file_path, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  bikes   R-squared:                       0.013\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     1.283\n",
      "Date:                Sun, 27 Aug 2023   Prob (F-statistic):              0.280\n",
      "Time:                        16:04:39   Log-Likelihood:                -630.14\n",
      "No. Observations:                 193   AIC:                             1266.\n",
      "Df Residuals:                     190   BIC:                             1276.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.6639      1.109      9.614      0.000       8.476      12.852\n",
      "fs_parks      -0.0470      0.058     -0.812      0.418      -0.161       0.067\n",
      "yelp_parks     0.0041      0.072      0.057      0.954      -0.138       0.146\n",
      "==============================================================================\n",
      "Omnibus:                       44.105   Durbin-Watson:                   2.043\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               89.249\n",
      "Skew:                           1.078   Prob(JB):                     4.17e-20\n",
      "Kurtosis:                       5.539   Cond. No.                         98.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Create a new DataFrame with predictors (fs_parks and yelp_parks) and the target variable (bikes)\n",
    "predictors = merged_df[['fs_parks', 'yelp_parks']]\n",
    "target = merged_df['bikes']\n",
    "\n",
    "# Add a constant term to the predictors\n",
    "predictors = sm.add_constant(predictors)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = sm.OLS(target, predictors)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide model output and an interpretation of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  bikes   R-squared:                       0.013\n",
    "Model:                            OLS   Adj. R-squared:                  0.003\n",
    "Method:                 Least Squares   F-statistic:                     1.283\n",
    "Date:                Sun, 27 Aug 2023   Prob (F-statistic):              0.280\n",
    "Time:                        01:00:21   Log-Likelihood:                -630.14\n",
    "No. Observations:                 193   AIC:                             1266.\n",
    "Df Residuals:                     190   BIC:                             1276.\n",
    "Df Model:                           2                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         10.6639      1.109      9.614      0.000       8.476      12.852\n",
    "fs_parks      -0.0470      0.058     -0.812      0.418      -0.161       0.067\n",
    "yelp_parks     0.0041      0.072      0.057      0.954      -0.138       0.146\n",
    "==============================================================================\n",
    "Omnibus:                       44.105   Durbin-Watson:                   2.043\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               89.249\n",
    "Skew:                           1.078   Prob(JB):                     4.17e-20\n",
    "Kurtosis:                       5.539   Cond. No.                         98.4\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is the summary of the linear regression analysis using the OLS (Ordinary Least Squares) method. It gives insights into how well the predictor variables (fs_parks and yelp_parks) explain the variability in the target variable (bikes). Here's an interpretation of the key information:\n",
    "\n",
    "R-squared: R-squared is a measure of how well the model's predictors explain the variation in the target variable. In this case, the R-squared value is 0.013, which indicates that only about 1.3% of the variability in bike availability is explained by the predictors (fs_parks and yelp_parks). The remaining variation is unaccounted for.\n",
    "\n",
    "Adj. R-squared: The adjusted R-squared value is similar to R-squared but accounts for the number of predictors in the model. It adjusts for the model's complexity. The value is 0.003, which is very close to the R-squared value in this case.\n",
    "\n",
    "F-statistic and Prob (F-statistic): The F-statistic tests whether the overall model is statistically significant. In this case, the F-statistic is 1.283 with a corresponding p-value of 0.280. Since the p-value is greater than the typical significance level (e.g., 0.05), it suggests that the overall model may not be statistically significant.\n",
    "\n",
    "Coefficients: The coefficients represent the estimated change in the dependent variable (bikes) for a one-unit change in each predictor, holding other predictors constant. For example:\n",
    "\n",
    "The constant (const) coefficient is 10.6639, which represents the predicted number of bikes when both fs_parks and yelp_parks are 0. The coefficient for fs_parks is -0.0470, indicating that a one-unit increase in fs_parks is associated with a decrease of 0.0470 in the predicted number of bikes. The coefficient for yelp_parks is 0.0041, indicating that a one-unit increase in yelp_parks is associated with an increase of 0.0041 in the predicted number of bikes. However, this coefficient is not statistically significant, as indicated by its high p-value. P-values: The p-values associated with each coefficient test whether the coefficients are statistically significant. A small p-value (typically < 0.05) suggests that the predictor variable has a significant impact on the dependent variable. In this case, both fs_parks and yelp_parks have p-values above 0.05, suggesting that neither predictor is statistically significant in explaining bike availability.\n",
    "\n",
    "Omnibus and JB Statistics: These are tests for normality of residuals. If the p-values are very small (<< 0.05), it suggests that the residuals are not normally distributed. In this case, the p-values are small, indicating potential deviations from normality.\n",
    "\n",
    "Durbin-Watson: This tests for the presence of autocorrelation in the residuals. A value around 2 suggests no autocorrelation. In this case, the value is around 2.043, indicating relatively low autocorrelation.\n",
    "\n",
    "Skew and Kurtosis: These values provide information about the shape of the distribution of residuals. Positive skewness (greater than 0) suggests a skewed distribution, and high kurtosis suggests heavy tails. In this case, there's positive skewness and relatively high kurtosis, indicating some deviation from a normal distribution.\n",
    "\n",
    "Overall, based on the coefficients, p-values, and R-squared value, the model suggests that the predictor variables (fs_parks and yelp_parks) have a limited ability to explain the variability in bike availability. The model's overall fit is weak, and both predictor variables are not statistically significant in predicting bike availability.\n",
    "\n",
    "Null Hypothesis (H0): The number of available bikes at a specific location is not significantly affected by the number of Foursquare parks and Yelp parks in that location.\n",
    "\n",
    "Alternative Hypothesis (H1): The number of available bikes at a specific location is significantly affected by the number of Foursquare parks and Yelp parks in that location.\n",
    "\n",
    "Hypothesis: In this hypothesis testing scenario, we assess whether the coefficients of the predictors (fs_parks and yelp_parks) are statistically significant. If the p-values associated with these coefficients fall below a predetermined significance level (usually 0.05), we can reject the null hypothesis and conclude that there is a significant relationship between the number of available bikes and the number of Foursquare parks and Yelp parks.\n",
    "\n",
    "From the summary output provided earlier, both fs_parks and yelp_parks exhibit p-values greater than 0.05. This implies that there is insufficient evidence to reject the null hypothesis, suggesting that the number of Foursquare parks and Yelp parks in a location might not significantly influence the number of available bikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you turn the regression model into a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the current regression problem into a classification task, I will redefine my objective to categorize the bike counts into different classes based on the characteristics of Points of Interest (POIs) in a location.\n",
    "\n",
    "Approach:\n",
    "\n",
    "Define Classes: I will start by determining the number of classes that I want to use for classifying the bike counts. For instance, I could opt for three classes: \"Low\", \"Medium\", and \"High\", each corresponding to different ranges of bike counts.\n",
    "\n",
    "Set Thresholds: Next, I will establish specific thresholds that will define the boundaries for each class. These thresholds will guide me in assigning bike counts to their respective classes. For example, \"Low\" might encompass bike counts from 0 to 10, \"Medium\" from 11 to 30, and \"High\" for counts exceeding 30.\n",
    "\n",
    "Assign Labels: Each data point will be labeled according to the determined thresholds. This process will involve assigning a class label to every observation based on where its bike count falls within the defined ranges. For instance, if a location's bike count is 5, it will be labeled as \"Low\".\n",
    "\n",
    "Select Classification Algorithm: I will select a suitable classification algorithm that can handle the transformed problem. Decision Trees, Random Forests, Support Vector Machines (SVM), and Logistic Regression are common options. I will then train the chosen algorithm on the labeled dataset.\n",
    "\n",
    "Feature Adaptation: I will review and adjust the features (predictors) used for classification as needed. These features can either remain the same as those in the regression problem or require modification to better align with the new classification context.\n",
    "\n",
    "Model Evaluation: After training the classification model, I will evaluate its performance using appropriate metrics such as accuracy, precision, recall, F1-score, and the confusion matrix. I will employ cross-validation techniques to assess the model's ability to generalize to new data.\n",
    "\n",
    "Refinement and Iteration: Based on the model's performance, I will make adjustments and refinements as necessary. This might involve tweaking the class count, modifying threshold values, experimenting with different classification algorithms, or introducing new features to enhance classification accuracy.\n",
    "\n",
    "Make Predictions: With a well-trained and evaluated classification model, I will be ready to make predictions on unseen data. These predictions will indicate the category of bike counts (e.g., \"Low\", \"Medium\", \"High\") rather than providing specific numerical values.\n",
    "\n",
    "By transitioning from a regression problem to a classification challenge, my focus will shift towards predicting the classification of bike counts into distinct categories. This approach will allow me to gain insights into broader patterns and trends in bike counts across various locations, rather than solely concentrating on exact numerical values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
